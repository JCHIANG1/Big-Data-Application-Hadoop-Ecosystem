#go to home directory to install hive, make sure that hive is install in the same level as hadoop
cd

#download the hive for instalation
wget http://rasinsrv07.cstcis.cti.depaul.edu/CSC555/apache-hive-2.0.1-bin.tar.gz
gunzip apache-hive-2.0.1-bin.tar.gz
tar xvf apache-hive-2.0.1-bin.tar

#set the enviorment variables (can be automated by adding these lines in ~/.bashrc)
#if we don't do this, we will have to set these variables everytime we use hive
export HIVE_HOME=/home/ec2-user/apache-hive-2.0.1-bin
export PATH=$HIVE_HOME/bin:$PATH

$HADOOP_HOME/bin/hadoop fs -mkdir /tmp 
$HADOOP_HOME/bin/hadoop fs -mkdir /user/hive/warehouse

#download the vehicle data
wget http://rasinsrv07.cstcis.cti.depaul.edu/CSC555/vehicles.csv

#2 ways to take a look at the data 
nano vehicles.csv 
more vehicles.csv ##you can press space to scroll and q or Ctrl-C to break out

#Create the ec2-user directory on the HDFS side 
hadoop fs -mkdir /user/ec2-user/




